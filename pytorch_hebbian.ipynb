{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb9b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import models\n",
    "from torchvision import datasets, transforms\n",
    "# from examples import DataLoader\n",
    "from examples import data  # 这是示例代码中的一个配置文件\n",
    "from pytorch_hebbian import config\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_hebbian.learning_rules import KrotovsRule\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from pytorch_hebbian import config\n",
    "from pytorch_hebbian.learning_rules import KrotovsRule\n",
    "from pytorch_hebbian.optimizers import Local\n",
    "from pytorch_hebbian.trainers import HebbianTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fc4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting training...\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, RandomSampler # 导入 RandomSampler\n",
    "\n",
    "# 假设这些是你项目中的模块\n",
    "from pytorch_hebbian import config\n",
    "from pytorch_hebbian.learning_rules import KrotovsRule\n",
    "from pytorch_hebbian.optimizers import Local\n",
    "from pytorch_hebbian.trainers import HebbianTrainer\n",
    "from pytorch_hebbian import utils # 导入 utils 来使用 get_device (可选但推荐)\n",
    "\n",
    "# --- 确定设备 ---\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    seed = 42 # 设定种子\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    seed = 42 # 设定种子\n",
    "    torch.manual_seed(seed)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 修改这里：创建与设备匹配的生成器 ---\n",
    "# 直接在创建时指定 device\n",
    "g = torch.Generator(device=device)\n",
    "g.manual_seed(seed) # 使用和全局一样的种子\n",
    "\n",
    "# Creating the model\n",
    "model = models.create_fc1_model([28 ** 2, 400])\n",
    "model.to(device)\n",
    "\n",
    "# Creating the dataset\n",
    "dataset = datasets.MNIST(root=config.DATASETS_DIR, download=True,\n",
    "                         transform=transforms.ToTensor())\n",
    "\n",
    "# 在 DataLoader 中使用 generator\n",
    "sampler = RandomSampler(dataset, generator=g)\n",
    "train_loader = DataLoader(dataset, batch_size=1024, sampler=sampler, shuffle=False) # shuffle=False 因为 sampler 已经随机了\n",
    "\n",
    "\n",
    "# Creating the learning rule, optimizer and trainer\n",
    "learning_rule = KrotovsRule()\n",
    "optimizer = Local(named_params=model.named_parameters(), lr=0.01)\n",
    "trainer = HebbianTrainer(model=model, learning_rule=learning_rule,\n",
    "                         optimizer=optimizer, device=device)\n",
    "\n",
    "# Running the trainer\n",
    "print(\"Starting training...\")\n",
    "trainer.run(train_loader=train_loader, epochs=1)\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3cc92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Hebbian training finished.\n",
      "\n",
      "Starting supervised training for the classifier layer...\n",
      "Froze parameters for layer 'linear1'.\n",
      "Supervised Epoch 1/5, Loss: 0.5305\n",
      "Supervised Epoch 2/5, Loss: 0.4913\n",
      "Supervised Epoch 3/5, Loss: 0.4781\n",
      "Supervised Epoch 4/5, Loss: 0.4666\n",
      "Supervised Epoch 5/5, Loss: 0.4628\n",
      "Supervised training finished.\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    }
   ],
   "source": [
    "# ... (你之前的代码保持不变) ...\n",
    "\n",
    "# Running the trainer\n",
    "print(\"Starting training...\")\n",
    "trainer.run(train_loader=train_loader, epochs=1) # 假设 Hebbian 训练已完成\n",
    "print(\"Hebbian training finished.\")\n",
    "\n",
    "# --- 开始添加评估部分 ---\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from pytorch_hebbian.evaluators import SupervisedEvaluator # 导入评估器\n",
    "\n",
    "print(\"\\nStarting supervised training for the classifier layer...\")\n",
    "\n",
    "# 1. 冻结 Hebbian 训练过的层 (假设是 model 中的第一个线性层 linear1)\n",
    "# 首先确认层的名字，根据 models.py 里的 create_fc1_model，它叫 'linear1'\n",
    "for name, param in model.named_parameters():\n",
    "    if 'linear1' in name: # 或者更精确地 if name.startswith('linear1.'):\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        # 确保其他层（特别是 linear2）是可训练的\n",
    "        param.requires_grad = True\n",
    "print(\"Froze parameters for layer 'linear1'.\")\n",
    "\n",
    "# 2. 定义损失函数和优化器 (只优化未冻结的参数，即 linear2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 只把需要训练的参数（linear2 的参数）传给优化器\n",
    "optimizer_sup = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "# 或者更明确地指定:\n",
    "# optimizer_sup = optim.Adam(model.linear2.parameters(), lr=1e-3) # 假设分类层叫 linear2\n",
    "\n",
    "# 3. 进行监督训练 (训练分类层 linear2)\n",
    "# 定义训练轮数\n",
    "supervised_epochs = 5 # 可以根据需要调整\n",
    "\n",
    "model.train() # 确保模型在训练模式\n",
    "for epoch in range(supervised_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): # 使用训练集 train_loader\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer_sup.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer_sup.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Supervised Epoch {epoch+1}/{supervised_epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Supervised training finished.\")\n",
    "\n",
    "# 4. 创建测试数据加载器 (你已经创建了 test_loader，但要确保数据集正确)\n",
    "# 加载 MNIST 测试集\n",
    "test_dataset = datasets.MNIST(root=config.DATASETS_DIR, train=False, download=True,\n",
    "                              transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False) # 测试时通常不打乱\n",
    "\n",
    "# 5. 创建评估器并进行评估\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "model.eval() # 切换到评估模式\n",
    "\n",
    "# 定义评估指标\n",
    "metrics = {\n",
    "    'accuracy': Accuracy(),\n",
    "    'loss': Loss(criterion) # 使用和监督训练一样的损失函数\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d4e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Loss: 0.9308 Accuracy: 0.7220\n"
     ]
    }
   ],
   "source": [
    "# 把之前定义的 criterion 作为第二个参数传进去\n",
    "evaluator = SupervisedEvaluator(model, criterion, metrics=metrics, device=device)\n",
    "\n",
    "# 在测试集上运行评估\n",
    "evaluator.run(test_loader)\n",
    "\n",
    "# 6. 打印结果\n",
    "# 通过 evaluator.engine 访问内部引擎的状态\n",
    "results = evaluator.engine.state.metrics\n",
    "accuracy = results['accuracy']\n",
    "avg_loss = results['loss']\n",
    "print(f\"Test Results - Loss: {avg_loss:.4f} Accuracy: {accuracy:.4f}\")\n",
    "# --- 评估部分结束 ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hebbian_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
